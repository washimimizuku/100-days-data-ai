# Day 97 Quiz: Model Optimization

## Questions

### Question 1
What is quantization in model optimization?

A) Removing unnecessary weights
B) Converting high-precision weights to lower precision
C) Training a smaller model
D) Compressing the model file

### Question 2
What is the main benefit of model pruning?

A) Improved accuracy
B) Reduced model size and faster inference
C) Better generalization
D) Easier training

### Question 3
What is knowledge distillation?

A) Removing water from the model
B) Training a smaller student model to mimic a larger teacher
C) Compressing model weights
D) Removing unnecessary layers

### Question 4
What is the typical precision reduction in quantization?

A) float64 to float32
B) float32 to int8
C) int32 to int16
D) float16 to float8

### Question 5
What is structured pruning?

A) Removing individual weights
B) Removing entire channels or neurons
C) Removing layers
D) Removing activations

### Question 6
What is the temperature parameter in knowledge distillation?

A) The training temperature
B) A scaling factor for softening probability distributions
C) The learning rate
D) The batch size

### Question 7
What is ONNX used for?

A) Training models
B) Cross-platform model deployment
C) Data preprocessing
D) Model evaluation

### Question 8
What is the trade-off in model optimization?

A) Speed vs memory
B) Accuracy vs size/speed
C) Training time vs inference time
D) Batch size vs latency

### Question 9
What is mixed precision training?

A) Using different optimizers
B) Using different data types for different operations
C) Training multiple models
D) Using different learning rates

### Question 10
What metric measures the effectiveness of compression?

A) Accuracy
B) Compression ratio (original size / compressed size)
C) Training time
D) Number of parameters

## Answer Key

1. B) Converting high-precision weights to lower precision
2. B) Reduced model size and faster inference
3. B) Training a smaller student model to mimic a larger teacher
4. B) float32 to int8
5. B) Removing entire channels or neurons
6. B) A scaling factor for softening probability distributions
7. B) Cross-platform model deployment
8. B) Accuracy vs size/speed
9. B) Using different data types for different operations
10. B) Compression ratio (original size / compressed size)

## Scoring Guide

- 10/10: Optimization Expert! Ready for production deployment
- 8-9/10: Strong understanding, review missed concepts
- 6-7/10: Good foundation, practice more with optimization
- Below 6: Review the material and exercises again
