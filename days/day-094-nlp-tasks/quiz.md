# Day 94 Quiz: NLP Tasks

## Questions

### Question 1
What is tokenization in NLP?

A) Converting text to lowercase
B) Breaking text into smaller units (words, subwords, characters)
C) Removing special characters
D) Translating text to another language

### Question 2
Which task involves identifying persons, organizations, and locations in text?

A) Sentiment analysis
B) Text classification
C) Named Entity Recognition (NER)
D) Text generation

### Question 3
What is the difference between extractive and abstractive summarization?

A) Extractive selects existing sentences, abstractive generates new text
B) They are the same thing
C) Extractive is always better
D) Abstractive only works on short texts

### Question 4
Which metric is commonly used to evaluate text generation quality?

A) Accuracy
B) BLEU score
C) IoU
D) F1-score

### Question 5
What does BERT stand for?

A) Basic Encoding Representation Transformer
B) Bidirectional Encoder Representations from Transformers
C) Binary Encoded Recurrent Transformer
D) Baseline Evaluation for Retrieval Tasks

### Question 6
In sentiment analysis, what are the typical output classes?

A) True/False
B) Positive/Negative/Neutral
C) High/Medium/Low
D) Yes/No/Maybe

### Question 7
What is the purpose of stopword removal?

A) To make text shorter
B) To remove common words that don't add much meaning
C) To improve spelling
D) To translate text

### Question 8
Which architecture is best for text generation tasks?

A) CNN
B) RNN
C) Autoregressive models like GPT
D) Decision trees

### Question 9
What does cosine similarity measure in text comparison?

A) The length of texts
B) The angle between text embedding vectors
C) The number of common words
D) The reading difficulty

### Question 10
What is the main advantage of using pre-trained language models?

A) They are smaller
B) They leverage knowledge from large-scale training
C) They only work in English
D) They don't need fine-tuning

## Answer Key

1. B) Breaking text into smaller units (words, subwords, characters)
2. C) Named Entity Recognition (NER)
3. A) Extractive selects existing sentences, abstractive generates new text
4. B) BLEU score
5. B) Bidirectional Encoder Representations from Transformers
6. B) Positive/Negative/Neutral
7. B) To remove common words that don't add much meaning
8. C) Autoregressive models like GPT
9. B) The angle between text embedding vectors
10. B) They leverage knowledge from large-scale training

## Scoring Guide

- 10/10: NLP Expert! Ready for advanced NLP applications
- 8-9/10: Strong understanding, review missed concepts
- 6-7/10: Good foundation, practice more with NLP
- Below 6: Review the material and exercises again
