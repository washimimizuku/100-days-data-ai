# Day 96 Quiz: Reinforcement Learning

## Questions

### Question 1
What are the main components of a reinforcement learning system?

A) Input and output
B) Agent, environment, state, action, reward
C) Model and data
D) Features and labels

### Question 2
What does the Q-function represent?

A) The quality of the environment
B) Expected return for taking an action in a state
C) The number of states
D) The probability of success

### Question 3
What is the exploration-exploitation tradeoff?

A) Balancing training time and accuracy
B) Balancing trying new actions vs using known good actions
C) Balancing model size and speed
D) Balancing data collection and processing

### Question 4
What is the discount factor (gamma) used for?

A) To reduce computational cost
B) To weight future rewards less than immediate rewards
C) To speed up training
D) To normalize rewards

### Question 5
What is epsilon-greedy action selection?

A) Always choosing the best action
B) Choosing random actions with probability epsilon, best action otherwise
C) Choosing actions based on their value
D) Choosing the most recent action

### Question 6
What is experience replay used for in DQN?

A) To save memory
B) To break correlation between consecutive samples
C) To speed up training
D) To reduce model size

### Question 7
What is the difference between value-based and policy-based methods?

A) Value-based learns Q-values, policy-based learns action probabilities
B) They are the same thing
C) Value-based is always better
D) Policy-based doesn't use rewards

### Question 8
What is the REINFORCE algorithm?

A) A value-based method
B) A policy gradient method
C) A model-based method
D) A supervised learning method

### Question 9
What is reward shaping?

A) Changing the environment
B) Designing rewards to guide learning
C) Normalizing rewards
D) Removing negative rewards

### Question 10
What is a Markov Decision Process (MDP)?

A) A type of neural network
B) A mathematical framework for RL with states, actions, transitions, rewards
C) A training algorithm
D) A type of environment

## Answer Key

1. B) Agent, environment, state, action, reward
2. B) Expected return for taking an action in a state
3. B) Balancing trying new actions vs using known good actions
4. B) To weight future rewards less than immediate rewards
5. B) Choosing random actions with probability epsilon, best action otherwise
6. B) To break correlation between consecutive samples
7. A) Value-based learns Q-values, policy-based learns action probabilities
8. B) A policy gradient method
9. B) Designing rewards to guide learning
10. B) A mathematical framework for RL with states, actions, transitions, rewards

## Scoring Guide

- 10/10: RL Expert! Ready for advanced RL applications
- 8-9/10: Strong understanding, review missed concepts
- 6-7/10: Good foundation, practice more with RL
- Below 6: Review the material and exercises again
